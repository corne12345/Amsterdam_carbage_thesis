{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "from bokeh.plotting import figure, show, save\n",
    "from bokeh.models import GeoJSONDataSource, ColumnDataSource, HoverTool\n",
    "from bokeh.io import export_png\n",
    "\n",
    "import shapely\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from Code.helper_functions import initial_loading\n",
    "from Code.loading_data import load_api_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Errors on loading API data\n",
    "It appeared that there were some problems regarding the loading of the data using the API. The connection got actively refused. After some testing a backup plan using a try-except clausule was implemented to prevent this from happening again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "load_api_data(prnt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api = pd.read_csv('../Data/afval_cluster.csv', delimiter=';')\n",
    "df_api = df_api[df_api['cluster_datum_einde_cluster'].isna()]\n",
    "df_api = df_api[['cluster_geometrie', 'cluster_fractie_aantal', 'cluster_fractie_volume', 'bag_adres_openbare_ruimte_naam', 'gbd_buurt_code']]\n",
    "df_api['cluster_x'] = df_api['cluster_geometrie'].apply(lambda x: x.split('(')[1].split(' ')[0])\n",
    "df_api['cluster_y'] = df_api['cluster_geometrie'].apply(lambda x: x.split()[1][:-1])\n",
    "df_api = df_api.drop(['cluster_geometrie'], axis=1).rename(columns={'cluster_fractie_aantal':'aantal_per_fractie', 'cluster_fractie_volume':'volume_per_fractie', 'bag_adres_openbare_ruimte_naam':'street_name', 'gbd_buurt_code':'buurt'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reassambling the score and penalty function\n",
    "There was some bad coding going on in terms of the score and penalty function. There was also new reassignment of the normalization factor. An optional parameter to print all factors instead of the total penalties was also added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to use addresses instead of clusters?True\n",
      "What stadsdeel do you want to make as a subsection(optional parameter)?\n",
      "What is the maximum amount of containers in a cluster that is considered to be useful?8\n",
      "Where to get db files(local/online)?local\n",
      "DB relation POIs loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\Code\\loading_data.py:342: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  verblijfsobjecten['bag'] = verblijfsobjecten['split'].apply(lambda x: x[3])\\\n",
      "..\\Code\\loading_data.py:361: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['ligtin_bag_pnd_identificatie'] = \\\n",
      "..\\Code\\loading_data.py:369: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  verblijfsobjecten['bag'] = verblijfsobjecten['bag'].astype('int64')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance matrix loaded\n",
      "API data loaded\n",
      "Table all households created\n",
      "API and DB joined\n",
      "containers per cluster determined\n"
     ]
    }
   ],
   "source": [
    "df_zo = pd.read_csv('../Results/20200510 - cluster optimization/hillclimber_best_config20200509-1228.csv')\n",
    "all_households, rel_poi_df, joined, df_afstandn2 = initial_loading()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Code.helper_functions import add_shortest_distances_to_all_households, analyze_candidate_solution\n",
    "from Code.loading_data import create_aansluitingen\n",
    "\n",
    "joined_cluster_distance = joined.set_index('s1_afv_nodes')\\\n",
    "    .join(df_afstandn2.set_index('van_s1_afv_nodes')).reset_index()\\\n",
    "    .rename(columns={'index': 'van_s1_afv_nodes'})\n",
    "\n",
    "good_result = \\\n",
    "    add_shortest_distances_to_all_households(all_households,\n",
    "                                             joined_cluster_distance,\n",
    "                                             use_count=True)\n",
    "\n",
    "aansluitingen = create_aansluitingen(good_result, joined_cluster_distance, use_count=True)\n",
    "\n",
    "joined_cluster_distance, good_result_rich, aansluitingen,avg_distance, penalties = analyze_candidate_solution(joined, all_households, rel_poi_df, df_afstandn2, clean=True, use_count=True, return_all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization of other fractions in places where garbage is collected from the curbs\n",
    "As nearly half of the city uses curbstone rest garbage collection, these can't just be excluded. Moreover, it also prevents dumping of undeseriable containers to these areas. The optional parameter clean has to be set to False for use. Its impact on the score function is to be determined further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = good_result[good_result['uses_container'] == False]\n",
    "# temp['rest_afstand'] = 9\n",
    "# temp['poi_rest'] = 9\n",
    "# good_result[good_result['uses_container']== False]['rest_afstand'] = 10\n",
    "# good_result[good_result['uses_container'] == False]['poi_rest'] = 10\n",
    "# good_result = good_result[good_result['uses_container'] == True]\n",
    "# good_result = good_result.append(temp)\n",
    "good_result.loc[~good_result['uses_container'], 'rest_afstand'] = np.nan\n",
    "good_result.loc[~good_result['uses_container'], 'poi_rest'] = np.nan\n",
    "good_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_cluster_distance = joined.set_index('s1_afv_nodes')\\\n",
    "    .join(df_afstandn2.set_index('van_s1_afv_nodes')).reset_index()\\\n",
    "    .rename(columns={'index': 'van_s1_afv_nodes'})\n",
    "\n",
    "good_result = \\\n",
    "    add_shortest_distances_to_all_households(all_households,\n",
    "                                             joined_cluster_distance,\n",
    "                                             use_count=True)\n",
    "\n",
    "aansluitingen = create_aansluitingen(good_result, joined_cluster_distance, use_count=True)\n",
    "\n",
    "joined_cluster_distance, good_result_rich, aansluitingen,avg_distance, penalties = analyze_candidate_solution(joined, all_households, rel_poi_df, df_afstandn2, clean=False, use_count=True, return_all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting of distances and penalties\n",
    "As optimization of just one of the parameters is possible within reasonable limits, the search arises for a way to compare these. One of the mentioned options was to optimize on one parameter, and hopefully find some point that is ideal. As the normal distance doesn't show anything, the best distance should be extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_optimization(filename):\n",
    "    df_plot1 = pd.read_csv(filename)\n",
    "    df_plot1['diff'] = df_plot1['penalties'] - df_plot1['best']\n",
    "    # df_plot1['total'] = df_plot1['avg_distance'] + df_plot1['penalties']\n",
    "    df_plot1['best_dist'] = df_plot1[df_plot1['diff'] < 0]['avg_distance']\n",
    "    df_plot1['best_dist'] = df_plot1['best_dist'].fillna(method='ffill')\n",
    "    ax = df_plot1['best_dist'].plot()\n",
    "    ax = df_plot1['best'].plot(secondary_y=True)\n",
    "    return ax\n",
    "    # ax = df_plot1['total'].plot(secondary_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plot_optimization('../Results/20200510 - cluster optimization/hillclimber20200509-1228.csv')\n",
    "fig1.set_title('Penalty-based optimization of Zuid-Oost with display of best average distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_optimization('../Results/20200510 - cluster optimization/hillclimber20200509-2116.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_optimization('../Results/20200510 - cluster optimization/hillclimber20200510-1050.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_optimization('../Results/20200510 - cluster optimization/hillclimber20200512-0813.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that an optimization approach where one of the parameters is chosen and constraints are set on the detoriation of the other may be an appropriate way to go. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight factors based on the amount of containers per fraction\n",
    "The summation of the penalties and walking distances for the different fractions is hard to make, as some kind of weighing needs to be applied. One of the new approaches would be to determine these weights based on the amount of containers that is present, as this would probably correlate with the amount of garbage produced and the relative importance of the different fractions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_clean = joined[joined['totaal'] < 9]\n",
    "temp = joined_clean[['rest', 'plastic', 'papier', 'glas', 'textiel', 'totaal']].sum()\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these numbers the weights would be assigned the following way: Rest(0.61458), Plastic(0.088776), Papier(0.15774), Glas(0.11350) and Textiel(0.025397). This will be set as the default value for the penalties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preventing the extra placement of Rest containers in light grey areas\n",
    "As there are certain areas where restafval is picked up, it doesn't make sense to place extra rest containers there. It should be set as a hard constraint that this is not possible, to prevent certain dumping of containers in these areas. The first snippet of code is added to the loading phases to keep track of the possibilities for each cluster to add rest containers. The constraint that move_rest has to be true is added to the optimization algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Code.loading_data import load_geodata_containers, address_in_service_area\n",
    "shapefile = load_geodata_containers()\n",
    "joined['move_rest'] = joined.apply(lambda row: address_in_service_area(row['cluster_x'], row['cluster_y'], polygon_list=shapefile), axis=1)\n",
    "# joined[~joined['move_rest']][['rest', 'plastic', 'papier', 'glas', 'textiel', 'totaal']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "r = joined\n",
    "mod_max = 5\n",
    "\n",
    "fractions = ['rest', 'plastic', 'papier', 'glas', 'textiel']\n",
    "no_modifications = random.randint(1, mod_max)\n",
    "#         print(no_modifications)\n",
    "for j in range(no_modifications):\n",
    "    valid = False\n",
    "    while not valid:\n",
    "        location_a = random.randint(0, r.shape[0]-1)\n",
    "        fraction_a = random.choice(fractions)\n",
    "        location_b = random.randint(0, r.shape[0]-1)\n",
    "        fraction_b = random.choice(fractions)\n",
    "        print(location_a, fraction_a, location_b, fraction_b, r.at[location_a, 'move_rest'])\n",
    "\n",
    "        if int(r.at[location_a, fraction_b]) > 0 and \\\n",
    "                int(r.at[location_b, fraction_a]) > 0 and \\\n",
    "                fraction_a != fraction_b and not (fraction_a == 'rest' and\n",
    "                                                  ~r.at[location_a, 'move_rest']):\n",
    "\n",
    "            r.at[location_a, fraction_a] = \\\n",
    "                int(r.at[location_a, fraction_a]) + 1\n",
    "            r.at[location_a, fraction_b] = \\\n",
    "                int(r.at[location_a, fraction_b]) - 1\n",
    "            r.at[location_b, fraction_a] = \\\n",
    "                int(r.at[location_b, fraction_a]) - 1\n",
    "            r.at[location_b, fraction_b] = \\\n",
    "                int(r.at[location_b, fraction_b]) + 1\n",
    "\n",
    "            valid = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
