{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import shapely\n",
    "from getpass import getpass\n",
    "\n",
    "import sys\n",
    "import copy\n",
    "sys.path.append(\"../Code\")\n",
    "\n",
    "from helper_functions import *\n",
    "from loading_data import *\n",
    "# from algorithms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfob= get_dataframe(\"\"\"\n",
    "                    SELECT bk_votpand_cluster, COUNT(*)\n",
    "                    FROM proj_afval_netwerk.rel_votpand_cluster_verblijfsobject\n",
    "                    GROUP BY bk_votpand_cluster\n",
    "                    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfob['split'] = dfob['bk_votpand_cluster'].str.split('~')\n",
    "dfob['bag'] = dfob['split'].apply(lambda x: x[0]).astype('int64')\n",
    "dfob['x'] = dfob['split'].apply(lambda x: x[1]).astype('float').round().astype('int')\n",
    "dfob['y'] = dfob['split'].apply(lambda x: x[2]).astype('float').round().astype('int')\n",
    "dfob = dfob.drop(['split'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_afstandn2 = get_dataframe(\"\"\"\n",
    "                                SELECT *\n",
    "                                FROM proj_afval_netwerk.afv_rel_nodes_poi\n",
    "                                \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_afstandn2['split'] = df_afstandn2['bk_afv_rel_nodes_poi'].str.split('~')\n",
    "df_afstandn2['x'] = df_afstandn2['split'].apply(lambda x: x[0]).astype('float').round().astype('int')\n",
    "df_afstandn2['y'] = df_afstandn2['split'].apply(lambda x: x[1]).astype('float').round().astype('int')\n",
    "df_afstandn2['type'] = df_afstandn2['split'].apply(lambda x: x[2])\n",
    "verblijfsobjecten = df_afstandn2[df_afstandn2['type'] != 'afval_cluster']\n",
    "verblijfsobjecten['bag'] = verblijfsobjecten['split'].apply(lambda x: x[3]).astype('int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = dfob.set_index(['bag', 'x', 'y']).join(verblijfsobjecten.set_index(['bag', 'x', 'y']), how='outer').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_afstandn = get_distance_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined= temp.set_index('s1_afv_nodes').join(df_afstandn.set_index('naar_s1_afv_nodes'), how='outer')\n",
    "joined = joined.reset_index()[['van_s1_afv_nodes', 'index', 'afstand', 'count']].\\\n",
    "         rename(columns={'index':'naar_s1_afv_nodes'}).sort_values(by='afstand').\\\n",
    "         reset_index().drop(['index'],axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_matrix_with_counts():\n",
    "    \"\"\"\n",
    "    Function that tries to match table with addresses per poi with \n",
    "    information and subsequently with distance matrix to give back\n",
    "    a distance matrix with the amount of households per addres poi.\n",
    "    \"\"\"\n",
    "    \n",
    "    dfob= get_dataframe(\"\"\"\n",
    "                    SELECT bk_votpand_cluster, COUNT(*)\n",
    "                    FROM proj_afval_netwerk.rel_votpand_cluster_verblijfsobject\n",
    "                    GROUP BY bk_votpand_cluster\n",
    "                    \"\"\")\n",
    "    \n",
    "    dfob['split'] = dfob['bk_votpand_cluster'].str.split('~')\n",
    "    dfob['bag'] = dfob['split'].apply(lambda x: x[0]).astype('int64')\n",
    "    dfob['x'] = dfob['split'].apply(lambda x: x[1]).astype('float').round().astype('int')\n",
    "    dfob['y'] = dfob['split'].apply(lambda x: x[2]).astype('float').round().astype('int')\n",
    "    dfob = dfob.drop(['split'], axis=1)\n",
    "    \n",
    "    df_afstandn2 = get_dataframe(\"\"\"\n",
    "                                SELECT *\n",
    "                                FROM proj_afval_netwerk.afv_rel_nodes_poi\n",
    "                                \"\"\")\n",
    "    \n",
    "    df_afstandn2['split'] = df_afstandn2['bk_afv_rel_nodes_poi'].str.split('~')\n",
    "    df_afstandn2['x'] = df_afstandn2['split'].apply(lambda x: x[0]).astype('float').round().astype('int')\n",
    "    df_afstandn2['y'] = df_afstandn2['split'].apply(lambda x: x[1]).astype('float').round().astype('int')\n",
    "    df_afstandn2['type'] = df_afstandn2['split'].apply(lambda x: x[2])\n",
    "    verblijfsobjecten = df_afstandn2[df_afstandn2['type'] != 'afval_cluster']\n",
    "    verblijfsobjecten['bag'] = verblijfsobjecten['split'].apply(lambda x: x[3]).astype('int64')\n",
    "    \n",
    "    temp = dfob.set_index(['bag', 'x', 'y']).join(verblijfsobjecten.set_index(['bag', 'x', 'y']), how='outer').reset_index()\n",
    "    df_afstandn = get_distance_matrix()\n",
    "    joined= temp.set_index('s1_afv_nodes').join(df_afstandn.set_index('naar_s1_afv_nodes'), how='outer')\n",
    "    joined = joined.reset_index()[['van_s1_afv_nodes', 'index', 'afstand', 'count']].\\\n",
    "             rename(columns={'index':'naar_s1_afv_nodes'}).sort_values(by='afstand').\\\n",
    "             reset_index().drop(['index'],axis=1).dropna()\n",
    "    \n",
    "    return joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = distance_matrix_with_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_households, rel_poi_df, joined, df_afstandn2 = initial_loading(use_count=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_afstandn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_cluster_distance = joined.set_index('s1_afv_nodes').join(df_afstandn2.set_index('van_s1_afv_nodes')).reset_index().rename(columns={'index': 'van_s1_afv_nodes'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_result_rich = add_shortest_distances_to_all_households(all_households, joined_cluster_distance, count=True)\n",
    "good_result_rich = good_result_rich[good_result_rich['uses_container']]\n",
    "good_result_rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aansluitingen = create_aansluitingen(good_result_rich, joined_cluster_distance, use_count=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_penalties(good_result, aansluitingen, use_count=False):\n",
    "    \"\"\"\n",
    "    This function calculates all the penalties associated with the candidate\n",
    "    solution. It does this by calculating the number of times all constraints\n",
    "    are violated and applies the weighing that is associated with all these\n",
    "    violations\n",
    "\n",
    "    Input:\n",
    "    dataframe good_result containing per adress or adress poi the distance\n",
    "    to the nearest container for all fractions.\n",
    "    dataframe aansluitingen containing for all clusters the amount of containers\n",
    "    per fraction, the amount of people using these containers and the percentage\n",
    "    of occupancy compared to the norm\n",
    "\n",
    "    Output:\n",
    "    The sum of all different penalties as a single float\n",
    "    \"\"\"\n",
    "    \n",
    "    penalty1 = good_result[good_result['rest_afstand'] > 100]\n",
    "    penalty2 = good_result[good_result['plastic_afstand'] > 150]\n",
    "    penalty3 = good_result[good_result['papier_afstand'] > 150]\n",
    "    penalty4 = good_result[good_result['glas_afstand'] > 150]\n",
    "    penalty5 = good_result[good_result['textiel_afstand'] > 300]\n",
    "    penalty6 = aansluitingen[aansluitingen['rest_perc'] > 100]\n",
    "    penalty7 = aansluitingen[aansluitingen['plastic_perc'] > 100]\n",
    "    penalty8 = aansluitingen[aansluitingen['papier_perc'] > 100]\n",
    "    penalty9 = aansluitingen[aansluitingen['glas_perc'] > 100]\n",
    "    penalty10 = aansluitingen[aansluitingen['textiel_perc'] > 100]\n",
    "    \n",
    "    if not use_count:\n",
    "        penalty1_sum = (penalty1['rest_afstand'].sum() - 100 * penalty1.shape[0])/good_result.shape[0] * 0.35\n",
    "        penalty2_sum = (penalty2['plastic_afstand'].sum() - 150 * penalty2.shape[0])/good_result.shape[0] * 0.25\n",
    "        penalty3_sum = (penalty3['papier_afstand'].sum() - 150 * penalty3.shape[0])/good_result.shape[0] * 0.2\n",
    "        penalty4_sum = (penalty4['glas_afstand'].sum() - 150 * penalty4.shape[0])/good_result.shape[0] * 0.15\n",
    "        penalty5_sum = (penalty5['textiel_afstand'].sum() - 300 * penalty5.shape[0])/good_result.shape[0] * 0.05\n",
    "        penalty6_sum = (penalty6['poi_rest'] - (penalty6['rest'] * 100)).sum()/ good_result.shape[0] * 0.35 * 1000\n",
    "        penalty7_sum = (penalty7['poi_plastic'] - (penalty7['plastic'] * 200)).sum()/ good_result.shape[0] * 0.25 * 1000\n",
    "        penalty8_sum = (penalty8['poi_papier'] - (penalty8['papier'] * 200)).sum()/ good_result.shape[0] * 0.2 * 1000\n",
    "        penalty9_sum = (penalty9['poi_glas'] - (penalty9['glas'] * 200)).sum()/ good_result.shape[0] * 0.15 * 1000\n",
    "        penalty10_sum = (penalty10['poi_textiel'] - (penalty10['textiel'] * 750)).sum()/ good_result.shape[0] * 0.05 * 1000\n",
    "        \n",
    "    else:\n",
    "        penalty1_sum = (penalty1['rest_afstand'].sum() - 100 * penalty1['count'].sum())/good_result['count'].sum() * 0.35\n",
    "        penalty2_sum = (penalty2['plastic_afstand'].sum() - 150 * penalty2['count'].sum())/good_result['count'].sum() * 0.25\n",
    "        penalty3_sum = (penalty3['papier_afstand'].sum() - 150 * penalty3['count'].sum())/good_result['count'].sum() * 0.2\n",
    "        penalty4_sum = (penalty4['glas_afstand'].sum() - 150 * penalty4['count'].sum())/good_result['count'].sum() * 0.15\n",
    "        penalty5_sum = (penalty5['textiel_afstand'].sum() - 300 * penalty5['count'].sum())/good_result['count'].sum() * 0.05\n",
    "        penalty6_sum = (penalty6['poi_rest'] - (penalty6['rest'] * 100)).sum()/ good_result['count'].sum() * 0.35 * 1000\n",
    "        penalty7_sum = (penalty7['poi_plastic'] - (penalty7['plastic'] * 200)).sum()/ good_result['count'].sum() * 0.25 * 1000\n",
    "        penalty8_sum = (penalty8['poi_papier'] - (penalty8['papier'] * 200)).sum()/ good_result['count'].sum() * 0.2 * 1000\n",
    "        penalty9_sum = (penalty9['poi_glas'] - (penalty9['glas'] * 200)).sum()/ good_result['count'].sum() * 0.15 * 1000\n",
    "        penalty10_sum = (penalty10['poi_textiel'] - (penalty10['textiel'] * 750)).sum()/ good_result['count'].sum() * 0.05 * 1000\n",
    "        \n",
    "    total_penalties = sum([penalty1_sum, penalty2_sum, penalty3_sum, penalty4_sum, penalty5_sum,\\\n",
    "                           penalty6_sum, penalty7_sum, penalty8_sum, penalty9_sum, penalty10_sum])\n",
    "    return total_penalties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_penalties(good_result_rich, aansluitingen, use_count=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial test for correctly loading data using count per poi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_households, rel_poi_df, joined, df_afstandn2 = initial_loading(use_count=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined, joined_cluster_distance, good_result_rich, aansluitingen, avg_distance, penalties = \\\n",
    "best_of_random(50, joined, all_households, rel_poi_df, df_afstandn2, clean=True, use_count=True)\n",
    "hill_dict, best_solution = hillclimber(1000, joined, all_households, rel_poi_df, df_afstandn2, clean=True, use_count=True, parameter='penalties')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined, joined_cluster_distance, good_result_rich, aansluitingen, avg_distance, penalties = \\\n",
    "best_of_random(10, joined, all_households, rel_poi_df, df_afstandn2, clean=True, use_count=True)\n",
    "hill_dict, best_solution = hillclimber(500, joined, all_households, rel_poi_df, df_afstandn2, clean=True, use_count=True, parameter='penalties')\n",
    "hill_df = pd.DataFrame.from_dict(hill_dict, orient='index')\n",
    "hill_df.to_csv('hillclimber.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_start_hillclimber(joined, all_households, rel_poi_df, df_afstandn2,\\\n",
    "                        parameter = 'penalties'):\n",
    "    i = int(input(\"How many random iterations?\"))\n",
    "    j = int(input(\"How many iterations hillclimber?\"))\n",
    "    to_save = bool(input(\"Do you want the results saved(True/False)?\"))\n",
    "    clean = bool(input(\"Do you want to only use a subset of data?\"))\n",
    "    use_count = bool(input(\"\"))\n",
    "    \n",
    "    \n",
    "    joined, joined_cluster_distance, good_result_rich, aansluitingen, \\\n",
    "        avg_distance, penalties = best_of_random(i, joined,all_households, \\\n",
    "        rel_poi_df, df_afstandn2, clean=clean, use_count=clean)\n",
    "    \n",
    "    hill_df, best_solution = hillclimber(j, joined, all_households, \\\n",
    "        rel_poi_df, df_afstandn2, clean=clean, use_count=use_count,\\\n",
    "        parameter=parameter, save=to_save)\n",
    "    hill_df['best'].plot()\n",
    "    return hill_df, best_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hill_df, best_solution = random_start_hillclimber(best_solution, all_households, rel_poi_df, df_afstandn2, use_count=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hillclimber(num_iterations, joined, all_households, rel_poi_df, df_afstandn2, mod_max = 5, parameter='score', complicated=True, clean=True, use_count=False, save=True):\n",
    "    \"\"\"\n",
    "    Function to perform repeated hillclimber. This can be added as a building block\n",
    "    directly to the standard solution, but also after for example a random algorithm.\n",
    "    The results are to be seen.\n",
    "    \"\"\"\n",
    "    joined_cluster_distance, good_result_rich, aansluitingen, avg_distance, penalties = analyze_candidate_solution(joined, all_households, rel_poi_df, df_afstandn2, clean=clean, use_count=use_count)\n",
    "\n",
    "    if parameter == 'score':\n",
    "        best = avg_distance + penalties\n",
    "    if parameter == 'penalties':\n",
    "        best = penalties\n",
    "\n",
    "    hillclimber_dict = {}\n",
    "    hillclimber_dict[0] = [avg_distance, penalties, best]\n",
    "\n",
    "    r = copy.deepcopy(joined)\n",
    "    for i in range(1, num_iterations+1):\n",
    "        last = copy.deepcopy(r)\n",
    "        fractions = ['rest', 'plastic', 'papier', 'glas', 'textiel']\n",
    "        no_modifications = random.randint(1, mod_max)\n",
    "#         print(no_modifications)\n",
    "        for j in range(no_modifications):\n",
    "            valid = False\n",
    "            while not valid:\n",
    "                location_a = random.randint(0, r.shape[0]-1)\n",
    "                fraction_a = random.choice(fractions)\n",
    "                location_b = random.randint(0, r.shape[0]-1)\n",
    "                fraction_b = random.choice(fractions)\n",
    "\n",
    "                if r.at[location_a, fraction_b] > 0 and r.at[location_b, fraction_a] > 0\\\n",
    "                                                    and fraction_a != fraction_b:\n",
    "                    r.at[location_a, fraction_a] = int(r.at[location_a, fraction_a]) + 1\n",
    "                    r.at[location_a, fraction_b] = int(r.at[location_a, fraction_b]) - 1\n",
    "                    r.at[location_b, fraction_a] = int(r.at[location_a, fraction_b]) - 1\n",
    "                    r.at[location_b, fraction_b] = int(r.at[location_a, fraction_b]) + 1\n",
    "                    valid = True\n",
    "\n",
    "        joined_cluster_distance2, good_result_rich2, aansluitingen2, avg_distance2, penalties2 = analyze_candidate_solution(r, all_households, rel_poi_df, df_afstandn2, clean=clean, use_count=use_count)\n",
    "        hillclimber_dict[i] = [avg_distance2, penalties2, best, no_modifications]\n",
    "        if parameter == 'score':\n",
    "            print(avg_distance2+penalties2, best)\n",
    "            if avg_distance2+penalties2 < best:\n",
    "                best = avg_distance2+penalties2\n",
    "            else:\n",
    "                r = copy.deepcopy(last) # Undo modification\n",
    "        if parameter == 'penalties':\n",
    "            print(penalties2, best)\n",
    "            if penalties2 < best:\n",
    "                best = penalties2\n",
    "            else:\n",
    "                r = copy.deepcopy(last) # Undo modification\n",
    "\n",
    "    hill_df = pd.DataFrame.from_dict(hillclimber_dict, orient='index')\n",
    "    hill_df = hill_df.rename(columns={0:'avg_distance', 1:'penalties', 2:'best', 3:'amount of modifications'})\n",
    "\n",
    "    if save:\n",
    "        today = str(pd.datetime.now().date()) + '-' + str(pd.datetime.now().hour)\n",
    "        hill_df.to_csv('hillclimber' + today + '.csv')\n",
    "        r.to_csv('hillclimber_best_config' + today + '.csv')\n",
    "\n",
    "    return hill_df, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = hill_df['best'].plot(title='Hillclimber plot of penalties score vs iterations')\n",
    "plt.set_xlabel('Number of iterations')\n",
    "plt.set_ylabel('Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
