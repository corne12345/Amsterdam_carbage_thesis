{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../Code\")\n",
    "\n",
    "from helper_functions import *\n",
    "from loading_data import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locations per cluster\n",
    "The first step is to slightly modify the loading of the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_api_data(prnt=False):\n",
    "    \"\"\"\n",
    "    This function loads in information on the current composition of container\n",
    "    clusters in Amsterdam. It uses the API from data.amsterdam.nl (available at\n",
    "    'https://api.data.amsterdam.nl/vsd/afvalclusters'). It returns the coordinates,\n",
    "    amount and volume of different fractions and the address of the clusters. As\n",
    "    a check, it is determined whether or not the cluster is currently active.\n",
    "    Returns:\n",
    "    - df containing coordinates, dict-like amount and volume per fraction and\n",
    "    address.\n",
    "    \"\"\"\n",
    "    x_coordinates = []\n",
    "    y_coordinates = []\n",
    "    aantal = []\n",
    "    volumes = []\n",
    "    adresses = []\n",
    "    buurt = []\n",
    "\n",
    "    link = 'https://api.data.amsterdam.nl/vsd/afvalclusters'\n",
    "\n",
    "    while link != None: #This is the case on the last page of the API\n",
    "        if prnt: # Can be used for some kind of monitoring of progres\n",
    "            print(link)\n",
    "        response = requests.get(link)\n",
    "        output = response.json()\n",
    "        for result in output['results']:\n",
    "            if result['cluster_datum_einde_cluster'] == None: #Als het cluster nog actief is\n",
    "                x_coordinates.append(str(result['cluster_geometrie']['coordinates'][0]))\n",
    "                y_coordinates.append(str(result['cluster_geometrie']['coordinates'][1]))\n",
    "                aantal.append(result['cluster_fractie_aantal'])\n",
    "                volumes.append(result['cluster_fractie_volume'])\n",
    "                adresses.append(result['bag_adres_openbare_ruimte_naam'])\n",
    "                buurt.append(result['gbd_buurt_code'])\n",
    "        try:\n",
    "            link = output['_links']['next']['href'] #Retrieve link for next page\n",
    "        except:\n",
    "            link = None #True for last page of API\n",
    "\n",
    "    df_clusters = pd.DataFrame([x_coordinates, y_coordinates, aantal, volumes, adresses, buurt]).T\n",
    "    df_clusters = df_clusters.rename(columns={0: 'cluster_x', 1:'cluster_y', 2:'aantal_per_fractie', 3:'volume_per_fractie', 4: 'street_name', 5:'buurt'})\n",
    "    # Transform coordinates of clusters to ints, as this helps easing join\n",
    "    df_clusters['cluster_x'] = df_clusters['cluster_x'].astype('float').round(0).astype('int')\n",
    "    df_clusters['cluster_y'] = df_clusters['cluster_y'].astype('float').round(0).astype('int')\n",
    "    df_clusters['wijk'] = df_clusters['buurt'].str[:3]\n",
    "    df_clusters['stadsdeel'] = df_clusters['buurt'].str[0]\n",
    "    return df_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_geodata_containers(subsectie=None):\n",
    "    \"\"\"\n",
    "    This function loads in all polygons representing areas in the city of Amsterdam\n",
    "    where general waste needs to be brought to a container. This is different\n",
    "    from the alternative where general waste is collected from the sidewalk. This\n",
    "    is needed to filter the address POI's to relevant POI's for optimization.\n",
    "    Subsectie is optional parameter to filter on specific stadsdelen. This can be used\n",
    "    for partial optimization.\n",
    "\n",
    "    Returns:\n",
    "    - List of polygons making up the area of centralized garbage collection\n",
    "    \"\"\"\n",
    "\n",
    "    source = gpd.read_file('../data/Inzameling_huisvuil_100220.shp')\n",
    "    source = source[source['aanbiedwij'] == 'Breng uw restafval  naar een container voor restafval.']\n",
    "    if subsectie:\n",
    "        source = source[source['sdcode'] == subsectie]\n",
    "    return list(source.geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db_afvalcluster_info():\n",
    "    \"\"\"\n",
    "    Function that modifies loads in data on the garbage clusters from the Postgres\n",
    "    database and modifies the resulting dataframe in a way that makes it usable\n",
    "    for future analysis\n",
    "    Returns:\n",
    "    - pandas DataFrame containing all information from the database and also the\n",
    "    added coordinates for the clusters and the type of POI\n",
    "    \"\"\"\n",
    "    polygon_list = load_geodata_containers()\n",
    "    db_df = get_dataframe(\"\"\"SELECT *\n",
    "                             FROM proj_afval_netwerk.afv_rel_nodes_poi\n",
    "                             \"\"\")\n",
    "    db_df['woning'] = db_df['bk_afv_rel_nodes_poi'].str.split('~')\n",
    "    db_df['cluster_x'] = db_df['woning'].apply(lambda x: x[0]).astype('float').round(0).astype('int')\n",
    "    db_df['cluster_y'] = db_df['woning'].apply(lambda x: x[1]).astype('float').round(0).astype('int')\n",
    "    db_df['type'] = db_df['woning'].apply(lambda x: x[2])\n",
    "    db_df['bag'] = db_df['woning'].apply(lambda x: x[3])\n",
    "    print('a')\n",
    "#     db_df['uses_container'] = db_df.apply(lambda row: address_in_service_area(row['cluster_x'], row['cluster_y'], polygon_list = polygon_list), axis=1)\n",
    "    db_df = db_df.drop('woning', axis=1)\n",
    "    return db_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_all_households(rel_poi_df, subsectie=None):\n",
    "    \"\"\"\n",
    "    Function that creates a dataframe containing all households as rows\n",
    "    \"\"\"\n",
    "    polygon_list = load_geodata_containers(subsectie = subsectie)\n",
    "    all_households = rel_poi_df[rel_poi_df['type']!='afval_cluster']\n",
    "    all_households = all_households[['s1_afv_nodes', 'cluster_x', 'cluster_y']]\n",
    "    print('b')\n",
    "    all_households['uses_container'] = all_households.apply(lambda row: address_in_service_area(row['cluster_x'], row['cluster_y'], polygon_list=polygon_list), axis=1)\n",
    "    return all_households"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters = load_api_data_neigborhood()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters['stadsdeel'].value_counts()\n",
    "# Stadsdeel Zuid-Oost (T) has 423 clusters. This is to be optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_poi_df = get_db_afvalcluster_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_households = create_all_households(rel_poi_df, subsectie='T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = join_api_db(rel_poi_df, df_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined['rest'], joined['plastic'], joined['papier'], joined['glas'], joined['textiel'], joined['totaal'] = zip(*joined['aantal_per_fractie'].apply(lambda x: containers_per_cluster(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_afstandn2 = distance_matrix_with_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['T', 'M', 'N', 'A', 'K', 'E', 'F', 'B']:\n",
    "    print(i)\n",
    "    all_households, rel_poi_df, joined, df_afstandn2 = initial_loading(use_count=True, subsectie=i)\n",
    "    joined_cluster_distance, good_result_rich, aansluitingen, avg_distance, penalties = \\\n",
    "    analyze_candidate_solution(joined, all_households, rel_poi_df, df_afstandn2, clean=True, use_count=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API data loaded\n",
      "DB relation POIs loaded\n",
      "Table all households created\n",
      "API and DB joined\n",
      "containers per cluster determined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../Code\\loading_data.py:239: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  verblijfsobjecten['bag'] = verblijfsobjecten['split'].apply(lambda x: x[3]).astype('int64')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance matrix loaded\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "random_start_hillclimber() got an unexpected keyword argument 'use_count'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-3748d975a8ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mall_households\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrel_poi_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjoined\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_afstandn2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitial_loading\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muse_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubsectie\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'T'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhill_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_solution\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_start_hillclimber\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoined\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_households\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrel_poi_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_afstandn2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: random_start_hillclimber() got an unexpected keyword argument 'use_count'"
     ]
    }
   ],
   "source": [
    "all_households, rel_poi_df, joined, df_afstandn2 = initial_loading(use_count=True, subsectie='T')\n",
    "hill_df, best_solution = random_start_hillclimber(joined, all_households, rel_poi_df, df_afstandn2, use_count=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
